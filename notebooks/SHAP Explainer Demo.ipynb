{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from keras.preprocessing import image\n",
    "import shap\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "MOUNTED_MODELS_ROOT = Path(\"/storage\")\n",
    "model_path = list(MOUNTED_MODELS_ROOT.glob(\"**/*.h5\"))[0]\n",
    "\n",
    "\n",
    "# Training config\n",
    "INPUT_SIZE = (224, 224)  # Default input size for VGG16\n",
    "CLASS_ENCODING = {\"Maltese dog\": 0, \"Afghan hound\": 1}\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_numpy(im, target_size) -> np.ndarray:\n",
    "    if isinstance(im, np.ndarray):\n",
    "        return im\n",
    "    if isinstance(im, bytes):\n",
    "        img_pil = Image.open(io.BytesIO(im))\n",
    "    if isinstance(im, (str, Path, io.BytesIO)):\n",
    "        img_pil = Image.open(im)\n",
    "        try:\n",
    "            img_pil = ImageOps.exif_transpose(image)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not isinstance(im, (str, Path, io.BytesIO, bytes, np.ndarray)):\n",
    "        raise ValueError(f\"Unexpected input type: {type(im)}\")\n",
    "    img_pil = img_pil.convert(\"RGB\")\n",
    "    img_pil = img_pil.resize(INPUT_SIZE, Image.NEAREST)\n",
    "    return image.img_to_array(img_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add SHAP js code to the notebook\n",
    "shap.initjs()\n",
    "\n",
    "# select files for explanation\n",
    "data_path = Path(os.environ[\"PROJECT\"]) / \"data\" / \"Images\"\n",
    "files_to_explain = list(data_path.glob(\"*.jpg\"))[0:4]\n",
    "inputs = np.array([img_to_numpy(file, target_size=INPUT_SIZE) for file in files_to_explain])\n",
    "\n",
    "# define a masker that is used to mask out partitions of the input image.\n",
    "masker = shap.maskers.Image(\"inpaint_telea\", inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define prediction function\n",
    "def predict_fn(x):\n",
    "    tmp = x.copy()\n",
    "    x = preprocess_input(tmp)\n",
    "    return model(tmp)\n",
    "\n",
    "# create an instance of explainer\n",
    "explainer = shap.Explainer(predict_fn, masker, output_names=list(CLASS_ENCODING.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain images using 500 evaluations of the underlying model to estimate the SHAP values\n",
    "shap_values = explainer(inputs, max_evals=500, batch_size=BATCH_SIZE, outputs=shap.Explanation.argsort.flip[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.image_plot(shap_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}