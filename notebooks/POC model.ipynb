{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce625407-b4d4-496b-a4fb-674bc7352ff0",
   "metadata": {},
   "source": [
    "# Download and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4545b4f-9d32-48c6-b05c-fe2d4a56e897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-19 16:15:16--  http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\n",
      "Resolving vision.stanford.edu (vision.stanford.edu)... 171.64.68.10\n",
      "Connecting to vision.stanford.edu (vision.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 793579520 (757M) [application/x-tar]\n",
      "Saving to: ‘/root/images.tar’\n",
      "\n",
      "/root/images.tar    100%[===================>] 756.82M  15.5MB/s    in 51s     \n",
      "\n",
      "2022-01-19 16:16:08 (14.7 MB/s) - ‘/root/images.tar’ saved [793579520/793579520]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar -O /root/images.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dce45ae-a8cf-4c5f-abbe-2c6f9997eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf /root/images.tar -C /root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096fbbb8-2859-4051-a02c-f8493025cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the breeds we care about. Get the first 100 images in those folders.\n",
    "!mkdir -p /root/data\n",
    "\n",
    "!(find /root/Images/n02088094-Afghan_hound -type f | head -100 | xargs -I f cp f /root/data)     \n",
    "!(find /root/Images/n02085936-Maltese_dog -type f | head -100 | xargs -I f cp f /root/data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f9f52b-3c6a-411f-b1a0-4048c7476c2d",
   "metadata": {},
   "source": [
    "# POC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38100f9b-99f7-4d50-9b24-016b1a78c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import re\n",
    "import io\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Union, List, Mapping\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import random as rn\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import models, layers, optimizers\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c43b39-67f6-46e1-971f-4a21f71050d9",
   "metadata": {},
   "source": [
    "## set seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60257959-272b-4d89-b281-3e6a3c141e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "rn.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a36377-77ec-41f3-a05c-4a56d19fda35",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35969dbe-114b-4bb9-acff-2ccfc5d0b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (224, 224)\n",
    "INPUT_LAYER_SHAPE = (7, 7, 512)\n",
    "CLASS_ENCODING = {\"Maltese dog\": 0, \"Afghan hound\": 1}\n",
    "ENCODING_CLASS = {0: \"Maltese dog\", 1: \"Afghan hound\"}\n",
    "FNAME_CLASS = {\"n02085936\": \"Maltese dog\", \"n02088094\": \"Afghan hound\"}\n",
    "RD_SEED = 1\n",
    "SPLIT_SEED = 42\n",
    "TEST_SIZE = 0.5\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75983b16-dcda-41b1-a1cd-06bd56cc911d",
   "metadata": {},
   "source": [
    "## Aux methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df66158e-538b-4ffb-9156-4e795fc04782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_numpy(\n",
    "    im: Union[str, Path, io.BytesIO, bytes, np.ndarray],\n",
    "    target_size: Union[int, int],\n",
    ") -> np.ndarray:\n",
    "    if isinstance(im, np.ndarray):\n",
    "        return im\n",
    "    if isinstance(im, bytes):\n",
    "        img_pil = Image.open(io.BytesIO(im))\n",
    "    if isinstance(im, (str, Path, io.BytesIO)):\n",
    "        img_pil = Image.open(im)\n",
    "        # capture and ignore this bug:\n",
    "        # https://github.com/python-pillow/Pillow/issues/3973\n",
    "        try:\n",
    "            img_pil = ImageOps.exif_transpose(image)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not isinstance(im, (str, Path, io.BytesIO, bytes, np.ndarray)):\n",
    "        raise ValueError(f\"Unexpected input type: {type(im)}\")\n",
    "    # Keras does not allow to process images in form of bytes\n",
    "    # https://github.com/keras-team/keras/issues/11684\n",
    "    img_pil = img_pil.convert(\"RGB\")\n",
    "    img_pil = img_pil.resize(INPUT_SIZE, Image.NEAREST)\n",
    "    return image.img_to_array(img_pil)\n",
    "\n",
    "class DogsDataset(Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: Path,\n",
    "        images: List[str],\n",
    "        labels: List[str],\n",
    "        class_encoding: Mapping[str, int],\n",
    "        batch_size=BATCH_SIZE,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        assert len(images) == len(labels)\n",
    "        self.dataset_path = dataset_path\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.class_encoding = class_encoding\n",
    "        self.sample_count = len(self.images)\n",
    "        self.indices = list(range(self.sample_count))\n",
    "        shuffle(self.indices)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def on_epoch_end(self, epoch=None, logs=None) -> None:\n",
    "        shuffle(self.indices)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return math.ceil(len(self.images) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        batch_indices = self.indices[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for bi in batch_indices:\n",
    "            img_name = Path(urlparse(self.images[bi]).path).name\n",
    "            img_path = self.dataset_path / img_name\n",
    "            x = img_to_numpy(img_path, target_size=INPUT_SIZE)\n",
    "            x = preprocess_input(x)\n",
    "            images.append(x)\n",
    "\n",
    "            labels.append(self.class_encoding[self.labels[bi]])\n",
    "\n",
    "        return (np.array(images), np.array(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0428555-5df3-4629-aeaa-e810eef69cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model() -> models.Model:\n",
    "    model = models.Sequential()\n",
    "    encoder = VGG16(weights=\"imagenet\", include_top=False, input_shape=(*INPUT_SIZE, 3))\n",
    "    encoder.trainable = False\n",
    "    model.add(encoder)\n",
    "    model.add(layers.Flatten(input_shape=INPUT_LAYER_SHAPE))\n",
    "    model.add(layers.Dense(256, activation=\"relu\", input_shape=INPUT_LAYER_SHAPE))\n",
    "    model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"acc\"],\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac39048-58dc-4066-b3e9-be66b3a90a5e",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c63c1188-11d0-4171-bef8-abe413cfbd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/root/data\")\n",
    "images = os.listdir(DATA_ROOT)\n",
    "labels = [\n",
    "    FNAME_CLASS[re.split(r\"/|_|.jpg\", str(f))[0]]\n",
    "    for f in images\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24a9c1c6-9266-43e9-802f-cdba68e3f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    images, labels, test_size=TEST_SIZE, stratify=labels, random_state=SPLIT_SEED\n",
    ")\n",
    "train_ds = DogsDataset(\n",
    "        DATA_ROOT,\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        CLASS_ENCODING,\n",
    ")\n",
    "validation_ds = DogsDataset(\n",
    "        DATA_ROOT,\n",
    "        X_test,\n",
    "        Y_test,\n",
    "        CLASS_ENCODING,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a952f69b-a9e4-415d-9640-94ebb7b0ed61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 16:20:37.058030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 16:20:37.068613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 16:20:37.070082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 16:20:37.072161: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-19 16:20:37.074123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 16:20:37.075519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 16:20:37.076891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 16:20:37.766155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 16:20:37.767607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 16:20:37.768985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 16:20:37.770374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38416 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:00:06.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6422784   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,137,986\n",
      "Trainable params: 6,423,298\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 16:20:40.871933: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8101\n",
      "2022-01-19 16:20:41.902878: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-01-19 16:20:41.904189: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-01-19 16:20:41.904249: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-01-19 16:20:41.904798: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-01-19 16:20:41.904910: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 15s - loss: 9.7468 - acc: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 16:20:44.415602: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 449ms/step - loss: 14.5058 - acc: 0.7200 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 2/4\n",
      "4/4 [==============================] - 1s 326ms/step - loss: 0.7604 - acc: 0.9900 - val_loss: 0.1522 - val_acc: 0.9900\n",
      "Epoch 3/4\n",
      "4/4 [==============================] - 1s 372ms/step - loss: 0.9100 - acc: 0.9800 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 4/4\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Validation Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_ds,\n",
    "    )\n",
    "\n",
    "final_val_acc = history.history[\"val_acc\"][-1]\n",
    "\n",
    "print(\"Validation Accuracy: %1.3f\" % (final_val_acc))\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
